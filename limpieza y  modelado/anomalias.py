"""
================================================================================
üö® DETECCI√ìN DE ANOMAL√çAS ROBUSTA (SIN REENTRENAR MODELOS)
================================================================================

Este m√≥dulo implementa un sistema de detecci√≥n de anomal√≠as para datos de
consumo de energ√≠a, agua y emisiones de CO2. Utiliza t√©cnicas estad√≠sticas
robustas basadas en mediana e IQR (rango intercuart√≠lico) para identificar
comportamientos an√≥malos sin necesidad de reentrenar modelos de machine learning.

Caracter√≠sticas principales:
  - Detecci√≥n contextual por hora del d√≠a
  - Normalizaci√≥n robusta usando mediana e IQR
  - Clasificaci√≥n en tres niveles: Normal, Alerta, Cr√≠tica
  - Funci√≥n de detecci√≥n para eventos individuales (chatbot)
  - Explicabilidad de anomal√≠as detectadas

Dependencias:
  - numpy: Operaciones num√©ricas
  - pandas: Manipulaci√≥n de datos

Autor(as): [Karol Acu√±a, Daniela Moreno, Sofia Torres, Juliana Garz√≥n]
Fecha: Enero 31 / 2026
================================================================================
"""

import numpy as np
import pandas as pd

print("\n" + "=" * 70)
print("üö® DETECCI√ìN DE ANOMAL√çAS ROBUSTA")
print("=" * 70)

# ================================================================
# SECCI√ìN 1: PREPARACI√ìN DE DATOS Y VARIABLES BASE
# ================================================================
# Este bloque copia el dataframe global y define las variables a analizar
# Se utiliza una copia para evitar modificaciones indeseadas en df_global

results = df_global.copy()
# DataFrame que contendr√° todas las m√©tricas de anomal√≠a
# DataFrame que contendr√° todas las m√©tricas de anomal√≠a

# Diccionario de variables a analizar con sus descripciones
variables = {
    'consumo_kwh': '‚ö° Energ√≠a',      # Consumo de energ√≠a en kilovatios-hora
    'agua_litros': 'üíß Agua',        # Consumo de agua en litros
    'co2_kg': 'üå± CO2'               # Emisiones de CO2 en kilogramos
}

# ================================================================
# SECCI√ìN 2: C√ÅLCULO DE SCORES ROBUSTOS POR VARIABLE
# ================================================================
# Se calcula el Z-score robusto usando mediana e IQR, agrupado por hora
# Esta normalizaci√≥n es resistente a outliers, a diferencia de Z-score cl√°sico
# F√≥rmula: Z_robusto = |valor - mediana| / IQR

for var in variables.keys():
    # Mediana por hora (medida de tendencia central resistente a outliers)
    mediana = results.groupby('hora')[var].transform('median')
    
    # Q3 y Q1 por hora (percentiles 75% y 25%)
    q75 = results.groupby('hora')[var].transform(lambda x: x.quantile(0.75))
    q25 = results.groupby('hora')[var].transform(lambda x: x.quantile(0.25))
    
    # Rango intercuart√≠lico (IQR) - medida de dispersi√≥n robusta
    # Se a√±ade 1e-6 para evitar divisi√≥n por cero
    iqr = (q75 - q25).replace(0, np.nan)
    
    # Z-score robusto: desviaci√≥n del valor respecto a la mediana, 
    # normalizada por el IQR
    results[f'{var}_z'] = np.abs(results[var] - mediana) / (iqr + 1e-6)

# ================================================================
# SECCI√ìN 3: C√ÅLCULO DEL SCORE GLOBAL DE ANOMAL√çA
# ================================================================
# Se combinan los tres scores individuales con pesos que reflejan su importancia
# Pesos: Energ√≠a (40%) > Agua (35%) > CO2 (25%)

results['anomalia_score_raw'] = (
    0.4 * results['consumo_kwh_z'] +    # 40%: Z-score de energ√≠a
    0.35 * results['agua_litros_z'] +   # 35%: Z-score de agua
    0.25 * results['co2_kg_z']          # 25%: Z-score de CO2
)
# Score combinado que representa la magnitud general de la anomal√≠a

# ================================================================
# SECCI√ìN 4: NORMALIZACI√ìN ROBUSTA CON LOGARITMO
# ================================================================
# Se aplica log1p (log(1+x)) para comprimir la escala de los scores
# Esto reduce el impacto de outliers extremos y facilita la interpretaci√≥n

results['anomalia_score'] = np.log1p(results['anomalia_score_raw'])
# anomalia_score es m√°s homog√©neo que anomalia_score_raw

# ================================================================
# SECCI√ìN 5: C√ÅLCULO DEL PERCENTIL POR CONTEXTO HORARIO
# ================================================================
# ELEMENTO CLAVE: Compara cada evento con su contexto hist√≥rico de la MISMA HORA
# Esto permite detectar anomal√≠as que var√≠an seg√∫n la hora del d√≠a
# Ejemplo: consumo de 5000 kWh es normal a las 12:00 pero an√≥malo a las 3:00

results['anomalia_percentil'] = (
    results
    .groupby('hora')['anomalia_score']
    .rank(pct=True)  # Ranking normalizado (0.0 a 1.0) dentro de cada hora
)
# anomalia_percentil: porcentaje de eventos por hora m√°s anomalosos que este

# ================================================================
# SECCI√ìN 6: CLASIFICACI√ìN FINAL EN TRES NIVELES
# ================================================================
# Basada en percentiles dentro del contexto horario:
#   - Normal: < 90 percentil (comportamiento t√≠pico)
#   - Alerta: 90-97 percentil (inusual pero no cr√≠tico)
#   - Cr√≠tica: > 97 percentil (muy an√≥malo, requiere atenci√≥n)

def clasificar_anomalia(p):
    """
    Clasifica el nivel de anomal√≠a bas√°ndose en el percentil.
    
    Args:
        p (float): Percentil del evento (0.0 a 1.0)
        
    Returns:
        str: Nivel de clasificaci√≥n ('Normal', 'Alerta' o 'Cr√≠tica')
    """
    if p < 0.90:
        return 'Normal'
    elif p < 0.97:
        return 'Alerta'
    else:
        return 'Cr√≠tica'

results['nivel_anomalia'] = results['anomalia_percentil'].apply(clasificar_anomalia)
# nivel_anomalia: clasificaci√≥n final de cada evento

# ================================================================
# SECCI√ìN 7: RESUMEN ESTAD√çSTICO DE ANOMAL√çAS DETECTADAS
# ================================================================
# Genera un informe general sobre la distribuci√≥n de anomal√≠as
# y el comportamiento de las variables por nivel de severidad

print("\nüìä Resumen de anomal√≠as (%)")
# Distribuci√≥n porcentual de eventos por nivel de severidad
print(
    results['nivel_anomalia']
    .value_counts(normalize=True)
    .mul(100)
    .round(2)
)

# Valores promedio de cada variable por nivel de severidad
for var, label in variables.items():
    print(f"\n{label} promedio")
    print(
        results
        .groupby('nivel_anomalia')[var]
        .mean()
    )

# ================================================================
# SECCI√ìN 8: IDENTIFICACI√ìN DE TOP 10 EVENTOS CR√çTICOS
# ================================================================
# Extrae y visualiza los 10 eventos m√°s an√≥malos del dataset
# √ötil para investigaci√≥n manual y auditor√≠a

print("\nüî• Top 10 eventos cr√≠ticos")

# Extrae eventos cr√≠ticos ordenados por severidad
top_criticos = (
    results[results['nivel_anomalia'] == 'Cr√≠tica']
    .sort_values('anomalia_score_raw', ascending=False)
    .head(10)[[
        'timestamp',
        'hora',
        'consumo_kwh',
        'agua_litros',
        'anomalia_score_raw',
        'anomalia_percentil',
        'co2_kg'
    ]]
)

# Mostrar tabla con los eventos m√°s cr√≠ticos
print(top_criticos.to_string())

# ================================================================
# SECCI√ìN 9: GUARDADO OPCIONAL DE RESULTADOS
# ================================================================
# Se puede guardar el dataframe con todas las m√©tricas de anomal√≠a en CSV
# Descomenta la siguiente l√≠nea para activar el guardado

# results.to_csv("anomalias_detectadas.csv", index=False)
# Salida: archivo CSV con timestamp, variables, scores y clasificaciones

print("\n" + "=" * 70)
print("‚úÖ DETECCI√ìN DE ANOMAL√çAS FINALIZADA CORRECTAMENTE")
print("   ‚úî Robusta (mediana + IQR)")
print("   ‚úî Contextual (por hora del d√≠a)")
print("   ‚úî Sin reentrenar modelos")
print("=" * 70)


# ================================================================
# PARTE 2: FUNCIONES PARA DETECCI√ìN DE ANOMAL√çAS EN CHATBOT
# ================================================================
# M√≥dulo separado para integraci√≥n con chatbots que necesitan evaluar
# eventos individuales en tiempo real sin recalcular todo el dataset

import numpy as np
import pandas as pd

# ================================================================
# SECCI√ìN 1: FUNCI√ìN PRINCIPAL - DETECTAR ANOMAL√çA DE UN EVENTO
# ================================================================

def detectar_anomalia_evento(
    df_ref,
    timestamp,
    hora,
    consumo_kwh,
    agua_litros,
    co2_kg
):
    """
    Detecta si un evento puntual es an√≥malo compar√°ndolo contra el hist√≥rico
    de la MISMA HORA del d√≠a.
    
    Algoritmo:
    1. Filtra datos hist√≥ricos de la misma hora
    2. Calcula Z-scores robustos para cada variable
    3. Combina scores con pesos predefinidos
    4. Normaliza con logaritmo
    5. Calcula percentil respecto al hist√≥rico
    6. Clasifica como Normal/Alerta/Cr√≠tica
    7. Identifica variables causantes de la anomal√≠a
    
    Args:
        df_ref (pd.DataFrame): DataFrame hist√≥rico con columnas 
                              'hora', 'consumo_kwh', 'agua_litros', 'co2_kg'
        timestamp (str): Timestamp del evento a evaluar (formato libre, solo informativo)
        hora (int): Hora del d√≠a (0-23)
        consumo_kwh (float): Consumo de energ√≠a en kWh
        agua_litros (float): Consumo de agua en litros
        co2_kg (float): Emisiones de CO2 en kg
        
    Returns:
        dict: Diccionario con claves:
              - 'timestamp': Timestamp del evento
              - 'nivel': Clasificaci√≥n ('Normal', 'Alerta', 'Cr√≠tica')
              - 'percentil': Percentil del evento (0-100)
              - 'score': Score num√©rico de anomal√≠a
              - 'explicacion': Lista de causas identificadas
              - 'mensaje': Mensaje opcional (si datos insuficientes)
    """

    # Filtra datos hist√≥ricos de la misma hora del d√≠a
    contexto = df_ref[df_ref['hora'] == hora]

    # Validaci√≥n: se requieren m√≠nimo 50 eventos para hacer una evaluaci√≥n confiable
    if len(contexto) < 50:
        return {
            "nivel": "Normal",
            "mensaje": "No hay suficientes datos hist√≥ricos para evaluar anomal√≠as."
        }

    def score_robusto(valor, serie):
        """
        Calcula Z-score robusto para un valor individual.
        Resistente a outliers usando mediana e IQR.
        
        Args:
            valor (float): Valor individual a evaluar
            serie (pd.Series): Serie hist√≥rica de referencia
            
        Returns:
            float: Z-score robusto normalizado
        """
        med = serie.median()
        iqr = serie.quantile(0.75) - serie.quantile(0.25)
        return abs(valor - med) / (iqr + 1e-6)

    # Calcula Z-scores robustos para cada variable
    z_consumo = score_robusto(consumo_kwh, contexto['consumo_kwh'])
    z_agua = score_robusto(agua_litros, contexto['agua_litros'])
    z_co2 = score_robusto(co2_kg, contexto['co2_kg'])

    # Score combinado ponderado
    score_raw = 0.4 * z_consumo + 0.35 * z_agua + 0.25 * z_co2
    # Normalizaci√≥n con log1p para comprimir escala
    score_final = np.log1p(score_raw)

    # Calcula los scores hist√≥ricos usando la misma f√≥rmula ponderada
    # para comparar el evento actual con la distribuci√≥n hist√≥rica
    scores_hist = (
        0.4 * abs(contexto['consumo_kwh'] - contexto['consumo_kwh'].median()) /
        (contexto['consumo_kwh'].quantile(0.75) - contexto['consumo_kwh'].quantile(0.25) + 1e-6)
        +
        0.35 * abs(contexto['agua_litros'] - contexto['agua_litros'].median()) /
        (contexto['agua_litros'].quantile(0.75) - contexto['agua_litros'].quantile(0.25) + 1e-6)
        +
        0.25 * abs(contexto['co2_kg'] - contexto['co2_kg'].median()) /
        (contexto['co2_kg'].quantile(0.75) - contexto['co2_kg'].quantile(0.25) + 1e-6)
    )

    # Percentil: porcentaje de eventos hist√≥ricos menos an√≥malos que el evento actual
    percentil = (scores_hist < score_raw).mean()

    # Clasificaci√≥n basada en percentiles (mismo umbral que en an√°lisis batch)
    if percentil < 0.90:
        nivel = "Normal"
    elif percentil < 0.97:
        nivel = "Alerta"
    else:
        nivel = "Cr√≠tica"

    # Identificaci√≥n de causas: examina qu√© variables provocaron la anomal√≠a
    # Un Z-score > 3 indica desviaci√≥n significativa
    causas = []
    if z_consumo > 3:
        causas.append("consumo energ√©tico inusualmente alto")
    if z_agua > 3:
        causas.append("consumo de agua fuera de lo normal")
    if z_co2 > 3:
        causas.append("emisiones de CO‚ÇÇ elevadas")

    # Si no hay causas individuales significativas, la anomal√≠a es por combinaci√≥n
    if not causas:
        causas.append("comportamiento combinado at√≠pico")

    return {
        "timestamp": timestamp,
        "nivel": nivel,
        "percentil": round(percentil * 100, 2),  # Convertir a escala 0-100
        "score": round(score_final, 2),           # Score normalizado
        "explicacion": causas                      # Causas de la anomal√≠a
    }

# ================================================================
# SECCI√ìN 2: SIMULACI√ìN DE ENTRADA DE USUARIO (EJEMPLO CHATBOT)
# ================================================================
# Ejemplo de datos que un usuario podr√≠a proporcionar al chatbot
# para verificar si un evento espec√≠fico es an√≥malo

evento_usuario = {
    "timestamp": "2025-06-24 12:00",    # Timestamp del evento a analizar
    "hora": 12,                         # Hora del d√≠a (para filtrar contexto)
    "consumo_kwh": 7200,                # Consumo de energ√≠a
    "agua_litros": 180000,              # Consumo de agua
    "co2_kg": 1600                      # Emisiones de CO2
}

# Ejecuta la detecci√≥n de anomal√≠a para el evento del usuario
resultado = detectar_anomalia_evento(
    df_ref=df_global,
    timestamp=evento_usuario["timestamp"],
    hora=evento_usuario["hora"],
    consumo_kwh=evento_usuario["consumo_kwh"],
    agua_litros=evento_usuario["agua_litros"],
    co2_kg=evento_usuario["co2_kg"]
)

# ================================================================
# SECCI√ìN 3: FUNCI√ìN DE RESPUESTA DEL CHATBOT (GENERACI√ìN DE TEXTO)
# ================================================================
# Convierte el resultado t√©cnico en un mensaje natural para el usuario
# Adapta el tono seg√∫n el nivel de severidad

def respuesta_chatbot(resultado):
    """
    Genera una respuesta natural en lenguaje conversacional para el usuario
    basada en los resultados de detecci√≥n de anomal√≠a.
    
    Args:
        resultado (dict): Diccionario retornado por detectar_anomalia_evento()
        
    Returns:
        str: Mensaje natural explicando si hay anomal√≠a y sus causas
    """
    # Caso Normal: consumo dentro de los par√°metros esperados
    if resultado["nivel"] == "Normal":
        return (
            f"‚úÖ El consumo registrado a las {resultado['timestamp']} "
            f"se encuentra dentro de los valores normales para esa hora."
        )

    # Prepara la lista de causas para incluir en el mensaje
    causas = ", ".join(resultado["explicacion"])

    # Caso Alerta: comportamiento inusual pero no cr√≠tico
    if resultado["nivel"] == "Alerta":
        return (
            f"‚ö†Ô∏è Atenci√≥n: el evento de las {resultado['timestamp']} "
            f"presenta un comportamiento inusual ({causas}). "
            f"Se encuentra en el percentil {resultado['percentil']}."
        )

    # Caso Cr√≠tica: anomal√≠a severa que requiere atenci√≥n inmediata
    return (
        f"üö® ALERTA CR√çTICA\n"
        f"El evento registrado a las {resultado['timestamp']} es altamente an√≥malo.\n"
        f"Motivos detectados: {causas}.\n"
        f"Nivel de severidad: percentil {resultado['percentil']}."
    )

# ================================================================
# SECCI√ìN 4: EJECUCI√ìN DEL EJEMPLO - RESPUESTA AL USUARIO
# ================================================================
# Genera y muestra la respuesta natural del chatbot para el evento de ejemplo

print("\nü§ñ Respuesta del chatbot:\n")
print(respuesta_chatbot(resultado))

# ================================================================
# FIN DEL M√ìDULO
# ================================================================
# Este script proporciona dos flujos de trabajo principales:
#
# 1. AN√ÅLISIS BATCH (Secciones 1-9 de la Parte 1):
#    - Procesa todo df_global de una vez
#    - Identifica tendencias generales de anomal√≠as
#    - Genera reportes de top 10 eventos cr√≠ticos
#
# 2. DETECCI√ìN EN TIEMPO REAL (Parte 2):
#    - Eval√∫a eventos individuales contra contexto hist√≥rico
#    - Ideal para integraci√≥n con chatbots
#    - Proporciona explicaciones naturales
#
# Caracter√≠sticas t√©cnicas:
# - Robusto frente a outliers (mediana + IQR)
# - Sensible al contexto (an√°lisis por hora)
# - Sin dependencia de modelos ML reentrenables
# - Interpretable y explicable
