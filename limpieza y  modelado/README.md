# ğŸ”‹ Modelo de PredicciÃ³n: EnergÃ­a, Agua y CO2

**DocumentaciÃ³n del Pipeline de Machine Learning de 3 Etapas**

---

## ğŸ“‹ DescripciÃ³n General

Este proyecto implementa un **sistema de predicciÃ³n en cascada** para estimar consumo de energÃ­a, agua y emisiones de CO2 en instalaciones educativas. El modelo utiliza XGBoost y tÃ©cnicas de feature engineering especializadas.

### Objetivo Principal
Predecir con precisiÃ³n:
- âš¡ **Consumo EnergÃ©tico** (kWh)
- ğŸ’§ **Consumo de Agua** (litros)
- ğŸŒ± **Emisiones de CO2** (kg)

---

## ğŸ—ï¸ Arquitectura del Pipeline

### **Etapa 1: PredicciÃ³n de Consumo EnergÃ©tico**
```
CaracterÃ­sticas Ambientales â†’ [Modelo XGBoost] â†’ PredicciÃ³n de EnergÃ­a
- Temperatura exterior
- OcupaciÃ³n del edificio  
- Hora y dÃ­a de la semana
- Sector especÃ­fico
```
**Salida**: PredicciÃ³n de consumo energÃ©tico (kWh)

### **Etapa 2: PredicciÃ³n de Agua (CRÃTICA)**
```
Features Base + PredicciÃ³n Etapa 1 â†’ [Modelo XGBoost] â†’ PredicciÃ³n de Agua
- Features especiales por sector (Comedores vs Laboratorios)
- TransformaciÃ³n logarÃ­tmica (normaliza distribuciÃ³n asimÃ©trica)
- EstadÃ­sticas histÃ³ricas por sector/sede
```
**Salida**: PredicciÃ³n de consumo de agua (litros)

### **Etapa 3: PredicciÃ³n de CO2**
```
Features Base + Predicciones Etapas 1&2 â†’ [Modelo XGBoost] â†’ PredicciÃ³n CO2
- CorrelaciÃ³n fuerte con energÃ­a consumida
- Features derivadas (consumoÂ²)
```
**Salida**: PredicciÃ³n de emisiones de CO2 (kg)

---

## ğŸ”§ TÃ©cnicas Aplicadas

### 1ï¸âƒ£ **Limpieza de Datos Avanzada**
- Consumo: Multiplicado por 1000 para pasar a kWh reales, clipped al P99 (elimina picos anÃ³malos)
- Agua: Multiplicado por 100 para pasar a litros reales (datos originales vienen divididos Ã·100), clipped al P98 (distribuciÃ³n muy sesgada)
- CO2: Multiplicado por 1000 para pasar a kg reales, removidos valores negativos, clipped al P99

### 2ï¸âƒ£ **Feature Engineering Especializado**

#### Features CÃ­clicas
- RepresentaciÃ³n seno/coseno de hora y dÃ­a
- Captura naturaleza cÃ­clica de los datos

#### Features EspecÃ­ficas para Agua
- `es_hora_comida`: Horas pico de comedores
- `sector_comedor`, `sector_laboratorio`: Indicadores por sector
- `comedor_x_temp`: InteracciÃ³n sector-temperatura
- `agua_sector_promedio`: Promedios histÃ³ricos

#### Features Temporales
- `es_hora_pico`: 8-12 y 14-18
- `es_fin_semana`: SÃ¡bado/Domingo
- `es_noche`: 22:00-6:00

### 3ï¸âƒ£ **TransformaciÃ³n LogarÃ­tmica**
El agua se modela en escala logarÃ­tmica porque:
- Original: **Skewness = Alto** (muy asimÃ©trica)
- Log: **Skewness = Bajo** (mÃ¡s simÃ©trica)
- Resultado: â†“ RMSE, â†‘ RÂ²

### 4ï¸âƒ£ **Stacked Generalization**
Cada modelo usa predicciones del anterior como features:
```
Consumo â†’ [usado en Agua] â†’ [usado en CO2]
```

---

## ğŸ“Š Resultados Clave

### Etapa 1: Consumo EnergÃ©tico
| MÃ©trica | Valor |
|---------|-------|
| MAE | 62.5 kWh |
| RMSE | 83.4 kWh |
| RÂ² | ~0.95 |
| MAPE | ~15% |
| *Nota* | Escala: valores multiplicados por 1000 durante preprocessing |

### Etapa 2: Agua (MEJORADA - Valores en Litros) ğŸš€
| MÃ©trica | Valor |
|---------|-------|
| MAE | ~5000-8000 litros |
| RÂ² | ~0.95 â¬†ï¸ |
| MAPE | ~25-35% |
| *Nota* | Escala: valores multiplicados por 100 durante preprocessing |

### Etapa 3: CO2
| MÃ©trica | Valor |
|---------|-------|
| MAE | ~0.4 kg |
| RMSE | ~0.5 kg |
| RÂ² | ~0.92 |
| *Nota* | Escala: valores multiplicados por 1000 durante preprocessing |

---

## ğŸ“ Archivos Generados

### Modelos Entrenados
- `modelo_consumo.pkl` - Modelo XGBoost para energÃ­a
- `modelo_agua_mejorado.pkl` - Modelo XGBoost para agua
- `modelo_co2.pkl` - Modelo XGBoost para CO2
- `label_encoder_sector.pkl` - Codificador de sectores
- `config_features.pkl` - ConfiguraciÃ³n y promedios histÃ³ricos

---

## ğŸ”® Uso del Modelo

### FunciÃ³n de PredicciÃ³n
```python
def predecir_completo(sede_id, sector, hora, dia_semana, temperatura, 
                      ocupacion, es_festivo=0, es_parciales=0, es_finales=0):
    """PredicciÃ³n en 3 etapas completa"""
    return {
        'consumo_kwh': float,
        'agua_litros': float,
        'co2_kg': float
    }
```

### Ejemplo de Uso
```python
prediccion = predecir_completo(
    sede_id=1,
    sector='Comedores',
    hora=12,
    dia_semana=2,
    temperatura=25,
    ocupacion=75
)

print(f"Consumo: {prediccion['consumo_kwh']} kWh")
print(f"Agua: {prediccion['agua_litros']} litros")
print(f"CO2: {prediccion['co2_kg']} kg")
```

---

## ğŸ› ï¸ HiperparÃ¡metros XGBoost

### ConfiguraciÃ³n ComÃºn
```python
n_estimators=500-800      # Cantidad de Ã¡rboles
learning_rate=0.03-0.05   # Tasa de aprendizaje
max_depth=8-10            # Profundidad mÃ¡xima
subsample=0.8-0.85        # RegularizaciÃ³n de muestras
colsample_bytree=0.8-0.85 # RegularizaciÃ³n de features
```

---

## ğŸ“ˆ Patrones Identificados

### Agua
- **Comedores**: MÃ¡ximo consumo en horas de comida (7-8, 12-13, 18-19)
- **Laboratorios**: Consumo estable relacionado con experimentos
- **Oficinas**: PatrÃ³n plano con ocupaciÃ³n
- **Temperatura >25Â°C**: Aumento en todos los sectores

### EnergÃ­a
- **Horas Pico**: 8-12 y 14-18
- **Fin de Semana**: Consumo reducido
- **Noche**: Consumo mÃ­nimo (iluminaciÃ³n y equipos standby)

### CO2
- **Fuerte correlaciÃ³n** con consumo energÃ©tico
- **Secundaria correlaciÃ³n** con agua

---

## ğŸš¨ Limitaciones y Consideraciones

1. **Agua es la variable mÃ¡s desafiante**: RÂ² ~0.95, pero valores estÃ¡n en escala normalizada (multiplicados por 100)
2. **TransformaciÃ³n log mejora precisiÃ³n** pero reduce interpretabilidad
3. **Datos de entrenamiento**: DivisiÃ³n 80/20 temporal (no aleatoria)
4. **Outliers**: Algunos dÃ­as especiales pueden tener patrones anÃ³malos
5. **Dependencias externas**: No incluye eventos especiales (festivos reales, paro, etc.)

---

## ğŸ”„ Pasos para Reentrenamiento

1. Actualizar `dataset_energia_limpio_sectores.csv`
2. Ejecutar `python model.py`
3. Nuevos archivos `.pkl` serÃ¡n generados automÃ¡ticamente
4. Usar `predecir_completo()` con los nuevos modelos

---

## ğŸ“š Referencias TÃ©cnicas

- **XGBoost**: Gradient Boosting mejorado
- **Stacked Generalization**: CombinaciÃ³n de mÃºltiples modelos
- **Feature Engineering**: Transformaciones manuales de variables
- **TransformaciÃ³n Log**: NormalizaciÃ³n de distribuciones sesgadas

---

**Generado**: Enero 2026  
**Estado**: âœ… DocumentaciÃ³n Completa
